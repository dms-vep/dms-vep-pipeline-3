{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd032799-f956-4da8-baad-43dff0af1046",
   "metadata": {},
   "source": [
    "# Fit `polyclonal` model to escape from antibody/serum or affinity soluble receptor\n",
    "In the notebook below, \"antibody\" is used as a synonym for any of antibody, serum, or soluble receptor.\n",
    "However, the plotting is done somewhat differently if we are trying to use escape from antibody/serum, or estimate how mutations affect the affinity by looking at their impact on inhibition by soluble receptor.\n",
    "\n",
    "Import Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653d04b-720e-4959-a8d8-006ce97190b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "import polyclonal\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0276731c-0a6f-4820-9edb-b61ab1e2ace8",
   "metadata": {},
   "source": [
    "This notebook is parameterized by `papermill`.\n",
    "The next cell is tagged as `parameters` to get the passed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd6a5a-5e55-4386-872b-ad9ce2af3d19",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged parameters for `papermill` parameterization\n",
    "assay = None\n",
    "selection = None\n",
    "params = None\n",
    "neut_standard_frac_csvs = None\n",
    "prob_escape_csvs = None\n",
    "prob_escape_mean_csv = None\n",
    "site_numbering_map_csv = None\n",
    "pickle_file = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2f3dc-c4c6-45ad-bb63-d420585e4649",
   "metadata": {},
   "source": [
    "## Read and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb6d48e-8f0e-4abf-9a2b-ea36311f5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Analyzing data for {assay=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03104424-09aa-44bb-b8b7-44a779d78c2e",
   "metadata": {},
   "source": [
    "Convert the antibody samples into a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76c6f9-e58b-41ca-9140-29e4bb868dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "antibody_samples = pd.DataFrame.from_dict(\n",
    "    params[\"antibody_samples\"], orient=\"index\"\n",
    ").reset_index(names=\"sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1441ef3-8166-4a11-9611-c443bf37173e",
   "metadata": {},
   "source": [
    "Get other parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68755860-59a5-4226-a4a1-91c5f4d3bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_escape_filters = {k: float(v) for k, v in params[\"prob_escape_filters\"].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7934ccf4-c133-4961-bb69-ee2bf16c9f5d",
   "metadata": {},
   "source": [
    "Read the neut standard fracs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff834ed-5f84-4ee1-89cb-a8f75acf00d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "neut_standard_fracs = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(f).assign(sample=sample)\n",
    "        for sample, f in zip(antibody_samples[\"sample\"], neut_standard_frac_csvs)\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ").merge(antibody_samples, validate=\"one_to_one\", on=\"sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c261ed-ac5d-48ff-a85f-8efbd7421e6f",
   "metadata": {},
   "source": [
    "Read the probabilities (fraction) escape for each variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a0bb4-e7ca-470c-b656-20820bf3a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_escape = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(f, keep_default_na=False, na_values=\"nan\").assign(sample=sample)\n",
    "        for sample, f in zip(antibody_samples[\"sample\"], prob_escape_csvs)\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ").merge(antibody_samples, validate=\"many_to_one\", on=\"sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72fd9de-8e6c-4009-a2ee-d8eb67ff6a18",
   "metadata": {},
   "source": [
    "## Plot the neutralization standard fractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e20527-c5d4-411e-b5d9-90b30fc1d50b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T23:24:52.535152Z",
     "iopub.status.busy": "2023-07-14T23:24:52.534646Z",
     "iopub.status.idle": "2023-07-14T23:24:52.547562Z",
     "shell.execute_reply": "2023-07-14T23:24:52.546970Z",
     "shell.execute_reply.started": "2023-07-14T23:24:52.535120Z"
    }
   },
   "source": [
    "Plot the neutralization standard fractions for each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc24e4c-e106-4bea-aba5-97eed3dbb61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neut_standard_fracs_chart = (\n",
    "    alt.Chart(\n",
    "        neut_standard_fracs.rename(\n",
    "            columns={\"antibody_frac\": \"antibody\", \"no-antibody_frac\": \"no-antibody\"}\n",
    "        ).melt(\n",
    "            id_vars=[\"sample\", \"use_in_fit\", \"concentration\"],\n",
    "            value_vars=[\"antibody\", \"no-antibody\"],\n",
    "            var_name=\"sample type\",\n",
    "            value_name=\"neutralization standard fraction\",\n",
    "        )\n",
    "    )\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            \"neutralization standard fraction\",\n",
    "            scale=alt.Scale(type=\"symlog\", constant=0.04, domainMax=1),\n",
    "        ),\n",
    "        y=alt.Y(\"sample\", sort=alt.SortField(\"concentration\"), title=None),\n",
    "        shape=alt.Shape(\"sample type\", title=\"sample type (filled if used in fit)\"),\n",
    "        stroke=alt.Color(\n",
    "            \"sample type\", scale=alt.Scale(range=[\"#1F77B4FF\", \"#FF7F0EFF\"])\n",
    "        ),\n",
    "        color=alt.Color(\n",
    "            \"sample type\", scale=alt.Scale(range=[\"#1F77B4FF\", \"#FF7F0EFF\"])\n",
    "        ),\n",
    "        fillOpacity=alt.Opacity(\n",
    "            \"use_in_fit\",\n",
    "            scale=alt.Scale(domain=[True, False], range=[1, 0]),\n",
    "        ),\n",
    "        tooltip=[\n",
    "            \"sample\",\n",
    "            alt.Tooltip(\"concentration\", format=\".3g\"),\n",
    "            alt.Tooltip(\"neutralization standard fraction\", format=\".3g\"),\n",
    "        ],\n",
    "    )\n",
    "    .mark_point(filled=True, size=50)\n",
    "    .configure_axis(labelLimit=500)\n",
    "    .properties(title=f\"Neutralization standard fractions for {selection}\")\n",
    ")\n",
    "\n",
    "neut_standard_fracs_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b801ab74-5214-4008-8a40-99b9cbeed763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T23:43:46.449840Z",
     "iopub.status.busy": "2023-07-14T23:43:46.449268Z",
     "iopub.status.idle": "2023-07-14T23:43:46.455263Z",
     "shell.execute_reply": "2023-07-14T23:43:46.454391Z",
     "shell.execute_reply.started": "2023-07-14T23:43:46.449800Z"
    }
   },
   "source": [
    "Make sure all samples used in the fit have enough neutralization standard counts and fraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ac90d9-7efd-43a6-a5eb-00476728e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prop in [\"count\", \"frac\"]:\n",
    "    minval = float(prob_escape_filters[f\"min_neut_standard_{prop}\"])\n",
    "    minval = float(minval)\n",
    "    if all(\n",
    "        (neut_standard_fracs.query(\"use_in_fit\")[f\"{stype}_{prop}\"] >= minval).all()\n",
    "        for stype in [\"antibody\", \"no-antibody\"]\n",
    "    ):\n",
    "        print(f\"Adequate neut_standard_{prop} of >= {minval}\")\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Inadequate neut_standard_{prop} < {minval}\\n{neut_standard_fracs}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088597e-8050-4e75-a663-4d280755b9f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T23:56:57.378541Z",
     "iopub.status.busy": "2023-07-14T23:56:57.378324Z",
     "iopub.status.idle": "2023-07-14T23:56:57.382676Z",
     "shell.execute_reply": "2023-07-14T23:56:57.382121Z",
     "shell.execute_reply.started": "2023-07-14T23:56:57.378522Z"
    }
   },
   "source": [
    "## Get variants with adequate counts to retain\n",
    "First get the minimum counts variants need to be retained: they need to meet this count threshold for **either** the antibody or no-antibody sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19a134-fdea-42ae-9a06-ea52ffe18403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minimum counts to be retained: needs to meet these for one of the samples\n",
    "min_counts = (\n",
    "    prob_escape.groupby(\"sample\", as_index=False)\n",
    "    .aggregate({\"antibody_count\": \"sum\", \"no-antibody_count\": \"sum\"})\n",
    "    .assign(\n",
    "        min_antibody_count=lambda x: (\n",
    "            (prob_escape_filters[\"min_antibody_frac\"] * x[\"antibody_count\"]).clip(\n",
    "                lower=prob_escape_filters[\"min_antibody_count\"],\n",
    "            )\n",
    "        ),\n",
    "        min_no_antibody_count=lambda x: (\n",
    "            (prob_escape_filters[\"min_no_antibody_frac\"] * x[\"no-antibody_count\"]).clip(\n",
    "                lower=prob_escape_filters[\"min_no_antibody_count\"],\n",
    "            )\n",
    "        ),\n",
    "    )[[\"sample\", \"min_antibody_count\", \"min_no_antibody_count\"]]\n",
    ")\n",
    "\n",
    "display(min_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00059c8-e850-4e83-83e2-0d85b08d2966",
   "metadata": {},
   "source": [
    "Now plot the distribution of no-antibody and antibody counts versus the thresholds.\n",
    "Recall we keep variants that meet **either** threshold, and in an ideal experiment all variants would meet the no-antibody threshold but we may expect only a small fraction (true escape mutations) to meet the antibody threshold.\n",
    "\n",
    "In the plots below, the bars span the interquartile range, the lines go from min to max, the dark black line is the median, and the red line is the threshold for counts to be retained (a variant only needs to meet one threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9adea5a-2ae1-40a6-92e4-1fcc7a3a8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_summary = (\n",
    "    prob_escape.melt(\n",
    "        id_vars=[\"sample\", \"concentration\", \"use_in_fit\"],\n",
    "        value_vars=[\"antibody_count\", \"no-antibody_count\"],\n",
    "        var_name=\"count_type\",\n",
    "        value_name=\"count\",\n",
    "    )\n",
    "    .groupby([\"sample\", \"concentration\", \"use_in_fit\", \"count_type\"], as_index=False)\n",
    "    .aggregate(\n",
    "        median=pd.NamedAgg(\"count\", \"median\"),\n",
    "        q1=pd.NamedAgg(\"count\", lambda s: s.quantile(0.25)),\n",
    "        q3=pd.NamedAgg(\"count\", lambda s: s.quantile(0.75)),\n",
    "        min=pd.NamedAgg(\"count\", \"min\"),\n",
    "        max=pd.NamedAgg(\"count\", \"max\"),\n",
    "    )\n",
    "    .merge(\n",
    "        min_counts.rename(\n",
    "            columns={\n",
    "                \"min_antibody_count\": \"antibody_count\",\n",
    "                \"min_no_antibody_count\": \"no-antibody_count\",\n",
    "            }\n",
    "        ).melt(id_vars=\"sample\", var_name=\"count_type\", value_name=\"threshold\"),\n",
    "        on=[\"sample\", \"count_type\"],\n",
    "        validate=\"one_to_one\",\n",
    "    )\n",
    ")\n",
    "\n",
    "base_chart = alt.Chart(count_summary).encode(\n",
    "    y=alt.Y(\"sample\", title=None, sort=alt.SortField(\"concentration\")),\n",
    "    tooltip=count_summary.columns.tolist(),\n",
    "    color=alt.Color(\n",
    "        \"use_in_fit\",\n",
    "        scale=alt.Scale(domain=[True, False], range=[\"blue\", \"gray\"]),\n",
    "    ),\n",
    ")\n",
    "\n",
    "quantile_bar = base_chart.encode(\n",
    "    x=alt.X(\n",
    "        \"q1\",\n",
    "        scale=alt.Scale(type=\"symlog\", constant=20),\n",
    "        axis=alt.Axis(labelOverlap=True),\n",
    "        title=\"count\",\n",
    "    ),\n",
    "    x2=\"q3\",\n",
    ").mark_bar(color=\"blue\", height={\"band\": 0.8})\n",
    "\n",
    "range_line = base_chart.encode(x=\"min\", x2=\"max\").mark_rule(color=\"blue\", opacity=0.5)\n",
    "\n",
    "median_line = base_chart.encode(\n",
    "    x=\"median\", x2=\"median\", color=alt.value(\"black\")\n",
    ").mark_bar(xOffset=1, x2Offset=-1, height={\"band\": 0.8})\n",
    "\n",
    "threshold_line = base_chart.encode(\n",
    "    x=\"threshold\", x2=\"threshold\", color=alt.value(\"red\")\n",
    ").mark_bar(xOffset=1, x2Offset=-1, height={\"band\": 0.8})\n",
    "\n",
    "count_summary_chart = (quantile_bar + range_line + median_line + threshold_line).facet(\n",
    "    column=alt.Column(\n",
    "        \"count_type\",\n",
    "        title=None,\n",
    "        sort=\"descending\",\n",
    "        header=alt.Header(labelFontWeight=\"bold\", labelFontSize=12),\n",
    "    ),\n",
    ")\n",
    "\n",
    "count_summary_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8603ac4-2f60-4afa-a0ad-c4ad299bc254",
   "metadata": {},
   "source": [
    "Classify which variants to retain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7220da07-67b1-4f84-8bbf-4c6feebedc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_escape = (\n",
    "    prob_escape.drop(\n",
    "        columns=[\"min_no_antibody_count\", \"min_antibody_count\"],\n",
    "        errors=\"ignore\",\n",
    "    )\n",
    "    .merge(min_counts, on=\"sample\", validate=\"many_to_one\")\n",
    "    .assign(\n",
    "        retain=lambda x: (\n",
    "            (x[\"antibody_count\"] >= x[\"min_antibody_count\"])\n",
    "            | (x[\"no-antibody_count\"] >= x[\"min_no_antibody_count\"])\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f8f118-e47f-4a80-a4d9-bb642720df68",
   "metadata": {},
   "source": [
    "Plot the fraction of all barcode counts and the fraction of all variants that are retained.\n",
    "We typically retain a higher fraction of barcode counts than variants, since the barcode counts are asymmetrically distributed toward some variants, which are more likely to be retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ed46c-c4cb-4df9-ae0d-299c3043c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_retained = (\n",
    "    prob_escape.melt(\n",
    "        id_vars=[\"sample\", \"concentration\", \"use_in_fit\", \"retain\", \"barcode\"],\n",
    "        value_vars=[\"antibody_count\", \"no-antibody_count\"],\n",
    "        var_name=\"count_type\",\n",
    "        value_name=\"count\",\n",
    "    )\n",
    "    .assign(retained_count=lambda x: x[\"count\"] * x[\"retain\"].astype(int))\n",
    "    .groupby([\"sample\", \"concentration\", \"use_in_fit\", \"count_type\"], as_index=False)\n",
    "    .aggregate(\n",
    "        counts=pd.NamedAgg(\"count\", \"sum\"),\n",
    "        retained_counts=pd.NamedAgg(\"retained_count\", \"sum\"),\n",
    "        variants=pd.NamedAgg(\"barcode\", \"count\"),\n",
    "        retained_variants=pd.NamedAgg(\"retain\", \"sum\"),\n",
    "    )\n",
    "    .assign(\n",
    "        barcode_counts=lambda x: x[\"retained_counts\"] / x[\"counts\"],\n",
    "        variants=lambda x: x[\"retained_variants\"] / x[\"variants\"],\n",
    "    )\n",
    "    .melt(\n",
    "        id_vars=[\"sample\", \"concentration\", \"use_in_fit\", \"count_type\"],\n",
    "        value_vars=[\"variants\", \"barcode_counts\"],\n",
    "        var_name=\"frac_type\",\n",
    "        value_name=\"fraction_retained\",\n",
    "    )\n",
    ")\n",
    "\n",
    "frac_retained_chart = (\n",
    "    alt.Chart(frac_retained)\n",
    "    .encode(\n",
    "        y=alt.Y(\"sample\", title=None, sort=alt.SortField(\"concentration\")),\n",
    "        x=alt.X(\"fraction_retained\", scale=alt.Scale(domain=[0, 1])),\n",
    "        yOffset=\"count_type\",\n",
    "        color=\"count_type\",\n",
    "        opacity=alt.Opacity(\n",
    "            \"use_in_fit\",\n",
    "            scale=alt.Scale(domain=[True, False], range=[1, 0.4]),\n",
    "        ),\n",
    "        column=alt.Column(\n",
    "            \"frac_type\",\n",
    "            title=None,\n",
    "            header=alt.Header(labelFontWeight=\"bold\", labelFontSize=12),\n",
    "        ),\n",
    "        tooltip=[\n",
    "            alt.Tooltip(c, format=\".3f\") if c == \"fraction_retained\" else c\n",
    "            for c in frac_retained.columns\n",
    "        ],\n",
    "    )\n",
    "    .mark_bar()\n",
    "    .properties(height=alt.Step(12), width=250)\n",
    ")\n",
    "\n",
    "frac_retained_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d376b8e-f158-4f40-88e4-df4fba6d1904",
   "metadata": {},
   "source": [
    "## Probability (fraction) escape among retained variants\n",
    "We now just analyze retained variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca122d00-c6c8-4aa3-81b9-414ebd96c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    prob_escape.query(\"retain\")\n",
    "    .groupby([\"sample\", \"concentration\"])\n",
    "    .aggregate(n_variants=pd.NamedAgg(\"barcode\", \"nunique\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae04f5-ef71-4780-9c0f-7c750d837dc1",
   "metadata": {},
   "source": [
    "Get mean probability of escape across all variants with the indicated number of mutations.\n",
    "Note we weight each retained variant equally regardless of how many barcode counts it has.\n",
    "We plot means for both the censored (set to between 0 and 1)and uncensored prob escape.\n",
    "Note that the plot uses a symlog scale for the y-axis.\n",
    "Mouseover points for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77945e16-6aee-4956-8661-d43e34265992",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_aa_subs = prob_escape_filters[\"max_aa_subs\"]\n",
    "\n",
    "mean_prob_escape = (\n",
    "    prob_escape.query(\"retain\")\n",
    "    .assign(\n",
    "        n_substitutions=lambda x: (\n",
    "            x[\"aa_substitutions\"]\n",
    "            .str.split()\n",
    "            .map(len)\n",
    "            .clip(upper=max_aa_subs)\n",
    "            .map(lambda n: str(n) if n < max_aa_subs else f\">{int(max_aa_subs - 1)}\")\n",
    "        ),\n",
    "        prob_escape_uncensored=lambda x: x[\"prob_escape_uncensored\"].clip(\n",
    "            upper=prob_escape_filters[\"clip_uncensored_prob_escape\"],\n",
    "        ),\n",
    "    )\n",
    "    .groupby(\n",
    "        [\"sample\", \"concentration\", \"use_in_fit\", \"n_substitutions\"], as_index=False\n",
    "    )\n",
    "    .aggregate(\n",
    "        prob_escape=pd.NamedAgg(\"prob_escape\", \"mean\"),\n",
    "        prob_escape_uncensored=pd.NamedAgg(\"prob_escape_uncensored\", \"mean\"),\n",
    "        n_variants=pd.NamedAgg(\"barcode\", \"count\"),\n",
    "    )\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"prob_escape\": \"censored to [0, 1]\",\n",
    "            \"prob_escape_uncensored\": \"not censored\",\n",
    "        }\n",
    "    )\n",
    "    .melt(\n",
    "        id_vars=[\n",
    "            \"sample\",\n",
    "            \"concentration\",\n",
    "            \"use_in_fit\",\n",
    "            \"n_substitutions\",\n",
    "            \"n_variants\",\n",
    "        ],\n",
    "        var_name=\"censored\",\n",
    "        value_name=\"probability escape\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Writing mean prob escape for samples used in fit to {prob_escape_mean_csv}\")\n",
    "mean_prob_escape.to_csv(prob_escape_mean_csv, index=False, float_format=\"%.4g\")\n",
    "\n",
    "mean_prob_escape_chart = (\n",
    "    alt.Chart(mean_prob_escape)\n",
    "    .encode(\n",
    "        x=alt.X(\"concentration\", scale=alt.Scale(type=\"log\")),\n",
    "        y=alt.Y(\n",
    "            \"probability escape\",\n",
    "            scale=(\n",
    "                alt.Scale(type=\"symlog\", constant=0.04)\n",
    "                if assay == \"antibody_escape\"\n",
    "                else alt.Scale()\n",
    "            ),\n",
    "        ),\n",
    "        column=alt.Column(\n",
    "            \"censored\",\n",
    "            title=None,\n",
    "            header=alt.Header(labelFontWeight=\"bold\", labelFontSize=12),\n",
    "        ),\n",
    "        color=alt.Color(\"n_substitutions\"),\n",
    "        tooltip=[\n",
    "            alt.Tooltip(c, format=\".3g\") if c == \"probability escape\" else c\n",
    "            for c in mean_prob_escape.columns\n",
    "        ],\n",
    "        shape=alt.Shape(\"use_in_fit\", scale=alt.Scale(domain=[True, False])),\n",
    "    )\n",
    "    .mark_line(point=True, size=0.75, opacity=0.8)\n",
    "    .properties(width=220, height=140)\n",
    "    .configure_axis(grid=False)\n",
    "    .configure_point(size=50)\n",
    ")\n",
    "\n",
    "mean_prob_escape_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068bcaf5-79ef-4ec3-96b5-6486b3b00c4c",
   "metadata": {},
   "source": [
    "## Fit `polyclonal` model\n",
    "Fit the model.\n",
    "If there is more than one epitope, we fit models with fewer epitopes too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f23ff-e121-4334-8dc7-011b3d4b3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first build up arguments used to specify fitting\n",
    "n_epitopes = params[\"polyclonal_params\"][\"n_epitopes\"]\n",
    "spatial_distances = params[\"polyclonal_params\"][\"spatial_distances\"]\n",
    "fit_kwargs = params[\"polyclonal_params\"][\"fit_kwargs\"]\n",
    "escape_plot_kwargs = params[\"escape_plot_kwargs\"]\n",
    "plot_hide_stats = params[\"plot_hide_stats\"]\n",
    "\n",
    "site_numbering_map = pd.read_csv(site_numbering_map_csv).sort_values(\"sequential_site\")\n",
    "\n",
    "if \"addtl_slider_stats\" not in escape_plot_kwargs:\n",
    "    escape_plot_kwargs[\"addtl_slider_stats\"] = {}\n",
    "if \"addtl_slider_stats_hide_not_filter\" not in escape_plot_kwargs:\n",
    "    escape_plot_kwargs[\"addtl_slider_stats_hide_not_filter\"] = []\n",
    "\n",
    "escape_plot_kwargs[\"df_to_merge\"] = []\n",
    "\n",
    "for stat, stat_d in plot_hide_stats.items():\n",
    "    escape_plot_kwargs[\"addtl_slider_stats\"][stat] = stat_d[\"init\"]\n",
    "    escape_plot_kwargs[\"addtl_slider_stats_hide_not_filter\"].append(stat)\n",
    "    merge_df = pd.read_csv(stat_d[\"csv\"]).rename(columns={stat_d[\"csv_col\"]: stat})\n",
    "    if \"min_filters\" in stat_d:\n",
    "        for col, col_min in stat_d[\"min_filters\"].items():\n",
    "            if col not in merge_df.columns:\n",
    "                raise ValueError(f\"{stat=} CSV lacks {col=}\\n{merge_df.columns=}\")\n",
    "            merge_df = merge_df[merge_df[col] >= col_min]\n",
    "    escape_plot_kwargs[\"df_to_merge\"].append(merge_df[[\"site\", \"mutant\", stat]])\n",
    "\n",
    "escape_plot_kwargs[\"df_to_merge\"].append(\n",
    "    site_numbering_map.rename(columns={\"reference_site\": \"site\"})[\n",
    "        [\"site\", \"sequential_site\", \"region\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "if assay == \"receptor_affinity\":\n",
    "    escape_plot_kwargs[\"scale_stat_col\"] = -1\n",
    "    escape_plot_kwargs[\"rename_stat_col\"] = \"receptor affinity\"\n",
    "\n",
    "if spatial_distances is not None:\n",
    "    print(f\"Reading spatial distances from {spatial_distances}\")\n",
    "    spatial_distances = pd.read_csv(spatial_distances)\n",
    "    print(f\"Read spatial distances for {len(spatial_distances)} residue pairs\")\n",
    "\n",
    "# now fit the models\n",
    "for n in range(1, n_epitopes + 1):\n",
    "    print(f\"\\n\\nFitting a model for {n} epitopes\")\n",
    "\n",
    "    model = polyclonal.Polyclonal(\n",
    "        n_epitopes=n,\n",
    "        data_to_fit=(\n",
    "            prob_escape.query(\"retain\").query(\"use_in_fit\")[\n",
    "                [\"aa_substitutions\", \"concentration\", \"prob_escape\"]\n",
    "            ]\n",
    "        ),\n",
    "        alphabet=polyclonal.AAS_WITHSTOP_WITHGAP,\n",
    "        spatial_distances=spatial_distances,\n",
    "        sites=site_numbering_map[\"reference_site\"],\n",
    "    )\n",
    "\n",
    "    opt_res = model.fit(**fit_kwargs)\n",
    "\n",
    "    print(\"Here is the neutralization curve:\")\n",
    "    display(model.curves_plot())\n",
    "    print(\"Here is the mutation-escape plot:\")\n",
    "    display(model.mut_escape_plot(**escape_plot_kwargs))\n",
    "\n",
    "print(f\"\\n\\nWriting the {n} epitope model to {pickle_file}\")\n",
    "with open(pickle_file, \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982c85f-f5c6-410d-97ca-9b6312fb67ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
